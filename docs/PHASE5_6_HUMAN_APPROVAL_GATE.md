# Phase 5.6 — Human Approval Gate (LLM → User Mediation)

**Design Lock — No Code**

---

## Purpose

Introduce an explicit **human approval boundary** between any LLM-generated output and user-visible content.

This phase ensures that:
- LLMs may assist internally
- Humans retain full authorship and decision authority
- No AI output reaches the user without conscious review and acceptance

This is the first phase where LLM output is *eligible* to become visible — but **only through human mediation**.

---

## Core Principle

> **LLMs may propose. Humans must approve. Nothing passes automatically.**

There is no implicit trust, no silent upgrades, and no background promotion of AI output.

---

## Scope

This phase governs:
- When LLM output may be shown to a human
- How it must be labeled and framed
- What happens when a human accepts, edits, or rejects it

It does **not** introduce automation, personalization, or persistence of decisions.

---

## Approval Gate Definition

An **Approval Gate** is a mandatory checkpoint where:

1. Deterministic system output is shown first
2. LLM-generated suggestions are shown second, clearly labeled
3. A human explicitly chooses one of the following actions:
   - Accept
   - Edit
   - Reject

No default action is allowed.

---

## Required UX Properties

All user-facing LLM content must:

- Be clearly labeled as **“AI-suggested”**
- Be visually separated from deterministic output
- Include an explicit approval control
- Require deliberate interaction (no auto-focus, no pre-selection)

Example labels:
- “AI suggestion (review before using)”
- “Draft generated by AI — not applied”

---

## Allowed Human Actions

A human may:

- ✅ Accept the AI suggestion as-is
- ✏️ Edit the suggestion before acceptance
- ❌ Reject the suggestion entirely

Each action is explicit and reversible.

---

## Explicitly Disallowed Behaviors

The system must not:

- Auto-apply LLM output
- Treat acceptance as endorsement of correctness
- Learn from acceptance or rejection
- Persist approval decisions as user preferences
- Suppress deterministic output when AI suggestions exist

---

## State & Memory Rules

- Approval decisions are **ephemeral**
- No long-term memory is created from approvals
- No personalization or preference inference is allowed
- Re-running the same input must require re-approval

---

## Language Guardrails (Enforced)

LLM output must not:

- Recommend actions (“You should apply…”)
- Assess suitability (“You are a strong fit…”)
- Predict outcomes (“You will likely get an interview…”)
- Compare the user to other candidates

Approved phrasing must remain descriptive and optional.

---

## Relationship to Prior Phases

This phase builds on:

- **Phase 5.3** — Language Guardrails
- **Phase 5.4** — Constrained LLM Participation
- **Phase 5.5** — Shadow Mode
- **Phase 5.5.1** — Prompt Test Harness

This phase **does not override** any earlier constraints.

---

## Completion Criteria

Phase 5.6 is considered complete when:

- A human approval step exists for all LLM-visible output
- No AI output can reach the user without interaction
- Deterministic output remains primary
- The system remains safe if the approval gate is bypassed or fails

---

## Non-Goals

This phase does not include:

- Automation
- Background learning
- Preference modeling
- Resume scoring
- Application submission
- “Smart defaults”

Any of the above require a new charter.

---

## Forward Boundary

> Any future phase that allows AI output to act *without* human approval
> requires explicit, named consent and a separate design document.

Next possible phase:
**Phase 5.7 — Explicit User Opt-In & Role Declaration**

