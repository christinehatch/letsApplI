# Phase 5.6 — Human Approval Gate (LLM → User Mediation)

**Design Lock — No Code**

---

## Purpose

Introduce an explicit **human approval boundary** between any LLM-generated output and user-visible content.

This phase ensures that:
- LLMs may assist internally
- Humans retain full authorship and decision authority
- No AI output reaches the user without conscious review and acceptance

This is the first phase where LLM output is *eligible* to become visible — but **only through human mediation**.

---

## Core Principle

> **LLMs may propose. Humans must approve. Nothing passes automatically.**

There is no implicit trust, no silent upgrades, and no background promotion of AI output.

---

## Scope

This phase governs:
- When LLM output may be shown to a human
- How it must be labeled and framed
- What happens when a human accepts, edits, or rejects it

It does **not** introduce automation, personalization, or persistence of decisions.

---

## Approval Gate Definition

An **Approval Gate** is a mandatory checkpoint where:

1. Deterministic system output is shown first
2. LLM-generated suggestions are shown second, clearly labeled
3. A human explicitly chooses one of the following actions:
   - Accept
   - Edit
   - Reject

No default action is allowed.

---

## Required UX Properties

All user-facing LLM content must:

- Be clearly labeled as **“AI-suggested”**
- Be visually separated from deterministic output
- Include an explicit approval control
- Require deliberate interaction (no auto-focus, no pre-selection)

Example labels:
- “AI suggestion (review before using)”
- “Draft generated by AI — not applied”

---

## Allowed Human Actions

A human may:

- ✅ Accept the AI suggestion as-is
- ✏️ Edit the suggestion before acceptance
- ❌ Reject the suggestion entirely

Each action is explicit and reversible.

---

## Explicitly Disallowed Behaviors

The system must not:

- Auto-apply LLM output
- Treat acceptance as endorsement of correctness
- Learn from acceptance or rejection
- Persist approval decisions as user preferences
- Suppress deterministic output when AI suggestions exist

---

## State & Memory Rules

- Approval decisions are **ephemeral**
- No long-term memory is created from approvals
- No personalization or preference inference is allowed
- Re-running the same input must require re-approval

---

## Language Guardrails (Enforced)

LLM output must not:

- Recommend actions (“You should apply…”)
- Assess suitability (“You are a strong fit…”)
- Predict outcomes (“You will likely get an interview…”)
- Compare the user to other candidates

Approved phrasing must remain descriptive and optional.

---

## Relationship to Prior Phases

This phase builds on:

- **Phase 5.3** — Language Guardrails
- **Phase 5.4** — Constrained LLM Participation
- **Phase 5.5** — Shadow Mode
- **Phase 5.5.1** — Prompt Test Harness

This phase **does not override** any earlier constraints.

---

## Completion Criteria

Phase 5.6 is considered complete when:

- A human approval step exists for all LLM-visible output
- No AI output can reach the user without interaction
- Deterministic output remains primary
- The system remains safe if the approval gate is bypassed or fails

---

## Non-Goals

This phase does not include:

- Automation
- Background learning
- Preference modeling
- Resume scoring
- Application submission
- “Smart defaults”

Any of the above require a new charter.

---

## Forward Boundary

> Any future phase that allows AI output to act *without* human approval
> requires explicit, named consent and a separate design document.

Next possible phase:
**Phase 5.7 — Explicit User Opt-In & Role Declaration**

# Phase 5.6 Addendum — Proposal Object & State Model (Design Lock)

## Purpose of This Addendum

This addendum defines the **minimum structural contract** for an AI-generated proposal that passes through the **Human Approval Gate**.

It exists solely to:

* Prevent implementation ambiguity
* Ensure review, approval, and rejection remain explicit
* Guarantee no hidden persistence or learning

This does **not** introduce personalization, memory, or automation.

---

## Proposal Object (Minimal Schema)

Every AI-generated suggestion that reaches the approval gate must be wrapped in a **Proposal** object.

```json
{
  "proposal_id": "uuid-or-hash",
  "source": "llm",
  "context": "job_gap_surfacing | evidence_mapping | phrasing_suggestion",
  "generated_at": "ISO-8601 timestamp",
  "status": "pending",
  "content": {
    "text": "AI-generated suggestion text",
    "notes": "Optional explanatory metadata (non-user-facing)"
  }
}
```

---

## Required Properties

### `proposal_id`

A unique identifier for this proposal instance only.

### `source`

Must be `"llm"`.

### `context`

Describes why the proposal exists (**never** what the user should do).

### `generated_at`

Timestamp for audit/debugging only.

### `status`

One of the allowed states defined below.

### `content.text`

The exact AI-generated text shown to the user (**unchanged**).

---

## Allowed Proposal States

A proposal may exist in **exactly one** of the following states:

| State      | Meaning                                     |
| ---------- | ------------------------------------------- |
| `pending`  | Generated by the LLM, awaiting human action |
| `accepted` | Human explicitly accepted as-is             |
| `edited`   | Human edited before accepting               |
| `rejected` | Human explicitly declined                   |

---

## State Invariants

* No proposal may skip `pending`
* No proposal may auto-transition
* Acceptance does not imply correctness
* Rejection does not imply error

---

## Persistence Rules (Explicit)

* Proposal objects are **ephemeral**
* They may exist only **in-session** or local transient state
* No proposal is stored after the interaction ends
* No proposal outcome is reused, replayed, or learned from
* No aggregation of approvals/rejections is permitted
* Deleting local state must fully reset the system

---

## Approval Semantics

### Accept

Uses the proposal verbatim as user-authored content.

### Edit

The edited result becomes user-authored; the original proposal is discarded.

### Reject

The proposal is discarded with no downstream effect.

At no point does the system infer preference, skill level, or intent from any choice.

---

## Explicit Non-Goals (Reaffirmed)

This addendum does not enable:

* Preference learning
* Resume scoring
* Suitability judgments
* Career advice
* Automated application steps
* Long-term memory

Any of the above requires a **new phase and charter**.

---

## Design Lock Statement

This proposal schema is intentionally minimal.
Any expansion of state, persistence, or inference requires a **new phase** and **explicit consent**.
